/* assembly to compute the poly1305 hash function using precomputed key powers
   and applying lazy reduction over a group of 16 message blocks */

#include "poly1271_macro.h"
	
	.p2align 5
	.globl poly1271_maax_g16
poly1271_maax_g16:

	movq 	%rsp,%r11
	andq    $-32,%rsp
	subq 	$96,%rsp

	movq 	%r11,0(%rsp)
	movq 	%r12,8(%rsp)
	movq 	%r13,16(%rsp)
	movq 	%r14,24(%rsp)
	movq 	%r15,32(%rsp)
	movq 	%rbx,40(%rsp)
	movq 	%rbp,48(%rsp)
	
	movq 	%rdi,56(%rsp)
	movq 	%r8,64(%rsp)
	movq 	%r9,%rax	

	cmpq    $1,%rcx
	je      .L1

	movq    %rdx,%rdi
	
	movq    $0,%r8
	movq    $0,%r9
	movq    $0,%r10
	movq    $0,%r11
	
	cmpq    $2,%rcx
	je      .LB2
	
	cmpq    $3,%rcx
	je      .LB3
	
	cmpq    $4,%rcx
	je      .LB4
	
	cmpq    $5,%rcx
	je      .LB5
	
	cmpq    $6,%rcx
	je      .LB6
	
	cmpq    $7,%rcx
	je      .LB7
	
	cmpq    $8,%rcx
	je      .LB8
	
	cmpq    $9,%rcx
	je      .LB9
	
	cmpq    $10,%rcx
	je      .LB10
	
	cmpq    $11,%rcx
	je      .LB11
	
	cmpq    $12,%rcx
	je      .LB12
	
	cmpq    $13,%rcx
	je      .LB13
	
	cmpq    $14,%rcx
	je      .LB14
	
	cmpq    $15,%rcx
	je      .LB15							
	
.LB16:
	mul_taun(0,224)
	add_product()	
	
	mul_taun(15,208)
	add_product()

	mul_taun(30,192)
	add_product()
	
	mul_taun(45,176)
	add_product()
	
	mul_taun(60,160)
	add_product()
	
	mul_taun(75,144)
	add_product()

	mul_taun(90,128)
	add_product()
	
	mul_taun(105,112)
	add_product()
	
	mul_taun(120,96)
	add_product()
	
	mul_taun(135,80)
	add_product()
	
	mul_taun(150,64)
	add_product()
	
	mul_taun(165,48)
	add_product()
	
	mul_taun(180,32)
	add_product()
	
	mul_taun(195,16)
	add_product()
	
	mul_taun(210,0)
	add_product()	
	     
	reduce_4limb()
	reduce_2limb()
	
	add_msg_block(225)
	
	addq	$240,%rsi
	subq    $16,%rcx
		
	cmpq    $0,%rcx	
	je      .LB0

.LT1:
	cmpq    $1,%rcx
	jg      .LT2
	
	mul_taunr(0)
	jmp     .LB1	

.LT2:
	cmpq    $2,%rcx	
	jg      .LT3	
	
	mul_taunr(16)
	jmp     .LB2

.LT3:
	cmpq    $3,%rcx
	jg      .LT4

	mul_taunr(32)
	jmp     .LB3
	
.LT4:
	cmpq    $4,%rcx
	jg      .LT5

	mul_taunr(48)
	jmp     .LB4
	
.LT5:
	cmpq    $5,%rcx
	jg      .LT6

	mul_taunr(64)
	jmp     .LB5
	
.LT6:
	cmpq    $6,%rcx
	jg      .LT7

	mul_taunr(80)
	jmp     .LB6
	
.LT7:
	cmpq    $7,%rcx
	jg      .LT8

	mul_taunr(96)
	jmp     .LB7
	
.LT8:
	cmpq    $8,%rcx
	jg      .LT9

	mul_taunr(112)
	jmp     .LB8
	
.LT9:
	cmpq    $9,%rcx
	jg      .LT10

	mul_taunr(128)
	jmp     .LB9
	
.LT10:
	cmpq    $10,%rcx
	jg      .LT11

	mul_taunr(144)
	jmp     .LB10
	
.LT11:
	cmpq    $11,%rcx
	jg      .LT12

	mul_taunr(160)
	jmp     .LB11
	
.LT12:
	cmpq    $12,%rcx
	jg      .LT13

	mul_taunr(176)
	jmp     .LB12
	
.LT13:
	cmpq    $13,%rcx
	jg      .LT14

	mul_taunr(192)
	jmp     .LB13
	
.LT14:
	cmpq    $14,%rcx
	jg      .LT15

	mul_taunr(208)
	jmp     .LB14
	
.LT15:
	cmpq    $15,%rcx
	jg      .LT16

	mul_taunr(224)
	jmp     .LB15												

.LT16:
	mul_taunr(240)
	jmp     .LB16

.LB1:	
	reduce_4limb()
		
	add_msg_block(0)
	
	addq	$15,%rsi	
		
	jmp     .LB0	
			
.LB2:
	mul_taun(0,0)
	add_product()
	
	reduce_4limb()
			
	add_msg_block(15)

	addq	$30,%rsi
	
	jmp     .LB0
	
.LB3:
	mul_taun(0,16)
	add_product()
		
	mul_taun(15,0)
	add_product()

	reduce_4limb()
			
	add_msg_block(30)

	addq	$45,%rsi
	
	jmp     .LB0	
	
.LB4:
	mul_taun(0,32)
	add_product()
		
	mul_taun(15,16)
	add_product()
	
	mul_taun(30,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(45)

	addq	$60,%rsi
	
	jmp     .LB0	
	
.LB5:
	mul_taun(0,48)
	add_product()
		
	mul_taun(15,32)
	add_product()
	
	mul_taun(30,16)
	add_product()
	
	mul_taun(45,0)
	add_product()		

	reduce_4limb()
			
	add_msg_block(60)

	addq	$75,%rsi
	
	jmp     .LB0	
	
.LB6:
	mul_taun(0,64)
	add_product()
		
	mul_taun(15,48)
	add_product()
	
	mul_taun(30,32)
	add_product()
	
	mul_taun(45,16)
	add_product()
	
	mul_taun(60,0)
	add_product()			

	reduce_4limb()
			
	add_msg_block(75)

	addq	$90,%rsi
	
	jmp     .LB0	
	
.LB7:
	mul_taun(0,80)
	add_product()
		
	mul_taun(15,64)
	add_product()
	
	mul_taun(30,48)
	add_product()
	
	mul_taun(45,32)
	add_product()
	
	mul_taun(60,16)
	add_product()
	
	mul_taun(75,0)
	add_product()				

	reduce_4limb()
			
	add_msg_block(90)

	addq	$105,%rsi
	
	jmp     .LB0
	
.LB8:
	mul_taun(0,96)
	add_product()
		
	mul_taun(15,80)
	add_product()
	
	mul_taun(30,64)
	add_product()
	
	mul_taun(45,48)
	add_product()
	
	mul_taun(60,32)
	add_product()
	
	mul_taun(75,16)
	add_product()
	
	mul_taun(90,0)
	add_product()					

	reduce_4limb()
			
	add_msg_block(105)

	addq	$120,%rsi
	
	jmp     .LB0
	
.LB9:
	mul_taun(0,112)
	add_product()
		
	mul_taun(15,96)
	add_product()
	
	mul_taun(30,80)
	add_product()
	
	mul_taun(45,64)
	add_product()
	
	mul_taun(60,48)
	add_product()
	
	mul_taun(75,32)
	add_product()
	
	mul_taun(90,16)
	add_product()
	
	mul_taun(105,0)
	add_product()						

	reduce_4limb()
			
	add_msg_block(120)

	addq	$135,%rsi
	
	jmp     .LB0
	
.LB10:
	mul_taun(0,128)
	add_product()
		
	mul_taun(15,112)
	add_product()
	
	mul_taun(30,96)
	add_product()
	
	mul_taun(45,80)
	add_product()
	
	mul_taun(60,64)
	add_product()
	
	mul_taun(75,48)
	add_product()
	
	mul_taun(90,32)
	add_product()
	
	mul_taun(105,16)
	add_product()
	
	mul_taun(120,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(135)

	addq	$150,%rsi
	
	jmp     .LB0
	
.LB11:
	mul_taun(0,144)
	add_product()
		
	mul_taun(15,128)
	add_product()
	
	mul_taun(30,112)
	add_product()
	
	mul_taun(45,96)
	add_product()
	
	mul_taun(60,80)
	add_product()
	
	mul_taun(75,64)
	add_product()
	
	mul_taun(90,48)
	add_product()
	
	mul_taun(105,32)
	add_product()
	
	mul_taun(120,16)
	add_product()
	
	mul_taun(135,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(150)

	addq	$165,%rsi
	
	jmp     .LB0
	
.LB12:
	mul_taun(0,160)
	add_product()
		
	mul_taun(15,144)
	add_product()
	
	mul_taun(30,128)
	add_product()
	
	mul_taun(45,112)
	add_product()
	
	mul_taun(60,96)
	add_product()
	
	mul_taun(75,80)
	add_product()
	
	mul_taun(90,64)
	add_product()
	
	mul_taun(105,48)
	add_product()
	
	mul_taun(120,32)
	add_product()
	
	mul_taun(135,16)
	add_product()
	
	mul_taun(150,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(165)

	addq	$180,%rsi
	
	jmp     .LB0
	
.LB13:
	mul_taun(0,176)
	add_product()
		
	mul_taun(15,160)
	add_product()
	
	mul_taun(30,144)
	add_product()
	
	mul_taun(45,128)
	add_product()
	
	mul_taun(60,112)
	add_product()
	
	mul_taun(75,96)
	add_product()
	
	mul_taun(90,80)
	add_product()
	
	mul_taun(105,64)
	add_product()
	
	mul_taun(120,48)
	add_product()
	
	mul_taun(135,32)
	add_product()
	
	mul_taun(150,16)
	add_product()
	
	mul_taun(165,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(180)

	addq	$195,%rsi
	
	jmp     .LB0
	
.LB14:
	mul_taun(0,192)
	add_product()
		
	mul_taun(15,176)
	add_product()
	
	mul_taun(30,160)
	add_product()
	
	mul_taun(45,144)
	add_product()
	
	mul_taun(60,128)
	add_product()
	
	mul_taun(75,112)
	add_product()
	
	mul_taun(90,96)
	add_product()
	
	mul_taun(105,80)
	add_product()
	
	mul_taun(120,64)
	add_product()
	
	mul_taun(135,48)
	add_product()
	
	mul_taun(150,32)
	add_product()
	
	mul_taun(165,16)
	add_product()
	
	mul_taun(180,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(195)

	addq	$210,%rsi
	
	jmp     .LB0
	
.LB15:
	mul_taun(0,208)
	add_product()
		
	mul_taun(15,192)
	add_product()
	
	mul_taun(30,176)
	add_product()
	
	mul_taun(45,160)
	add_product()
	
	mul_taun(60,144)
	add_product()
	
	mul_taun(75,128)
	add_product()
	
	mul_taun(90,112)
	add_product()
	
	mul_taun(105,96)
	add_product()
	
	mul_taun(120,80)
	add_product()
	
	mul_taun(135,64)
	add_product()
	
	mul_taun(150,48)
	add_product()
	
	mul_taun(165,32)
	add_product()
	
	mul_taun(180,16)
	add_product()
	
	mul_taun(195,0)
	add_product()	

	reduce_4limb()
			
	add_msg_block(210)

	addq	$225,%rsi
	
	jmp     .LB0	
	
.LB0:	
	cmpq	$0,64(%rsp)
	jg	.L0
	
	subq	$15,%rsi
	movq    0(%rsi),%r10
	movq    8(%rsi),%r11
	movq    %r11,%r12
	andq    mask56(%rip),%r11
	orq     c(%rip),%r11

	subq    %r10,%r8
	sbbq    %r11,%r9

	addq    %r10,%r8
	adcq    %r12,%r9		

.L0:
	mul_taunr(0)

	reduce_4limb()
			
	jmp	.LF

.L1:   
	movq    0(%rdx),%r14
	movq    8(%rdx),%r15

	movq    0(%rsi),%r13
	movq    8(%rsi),%r12

	cmpq    $8,%rax
	jle     .L3
	
	cmpq    $0,64(%rsp)
	je      .L2
	
	andq    mask56(%rip),%r12
	orq     c(%rip),%r12	
	
.L2:	
	xorq    %r11,%r11
	movq    %r13,%rdx    

	mulx    %r14,%r8,%r9  
	mulx    %r15,%rbx,%r10
	adcx    %rbx,%r9
	adcx    %r11,%r10     

	movq    %r12,%rdx
	xorq    %r12,%r12	
	   
	mulx    %r14,%rbx,%rbp
	adcx    %rbx,%r9
	adox    %rbp,%r10
	    
	mulx    %r15,%rbx,%rbp
	adcx    %rbx,%r10
	adox    %rbp,%r11
	adcx    %r12,%r11

	reduce_4limb()
			
	jmp     .LF

.L3:    
	xorq    %r11,%r11
	movq    %r13,%rdx    

	mulx    %r14,%r8,%r9
	mulx    %r15,%rbx,%r10
	adcx    %rbx,%r9
	adcx    %r11,%r10

	reduce_4limb()

.LF:	
	reduce_2limb()
	
	make_unique()

	andq    mask62(%rip),%r9	
	movq 	56(%rsp),%rdi
	movq    %r8,0(%rdi)
	movq    %r9,8(%rdi)

	movq 	0(%rsp),%r11
	movq 	8(%rsp),%r12
	movq 	16(%rsp),%r13
	movq 	24(%rsp),%r14
	movq 	32(%rsp),%r15
	movq 	40(%rsp),%rbx
	movq 	48(%rsp),%rbp

	movq 	%r11,%rsp

	ret
